{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T13:44:04.014284Z",
     "start_time": "2018-04-01T13:44:03.293233Z"
    },
    "scrolled": false
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook first generates standardized names from fantasy salary information by querying Basketball-Reference.com, and then merge two datasets while adding fantasy stats based on DraftKings rules. Position information is also modified and added from salary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:05.924554Z",
     "start_time": "2019-05-26T09:32:05.420122Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from utils\n",
    "from constants import DATA_DIR, SECONDS_SLEEP, DF_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:07.439131Z",
     "start_time": "2019-05-26T09:32:07.435317Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Fantasy Stats from Boxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:45.478854Z",
     "start_time": "2019-05-26T09:32:45.465708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add additional columns for double double (DD) and triple double (TD)\n",
    "# Double digit in two or three of points, rebounds, assists, steals and blocks\n",
    "def add_doubles(df):\n",
    "    dd = [0 for i in range(df.shape[0])]\n",
    "    td = [0 for i in range(df.shape[0])]\n",
    "    \n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        doubles_count = 0\n",
    "        check_doubles = ['PTS','TRB', 'AST', 'STL', 'BLK']\n",
    "        \n",
    "        for stat in check_doubles:\n",
    "            if df.loc[i, stat] >= 10:\n",
    "                doubles_count += 1\n",
    "        \n",
    "        if doubles_count >= 2:\n",
    "            dd[i] = 1\n",
    "        if doubles_count >= 3:\n",
    "            td[i] = 1\n",
    "   \n",
    "    df['DD'] = dd\n",
    "    df['TD'] = td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Position Information on Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:47.683228Z",
     "start_time": "2019-05-26T09:32:47.676459Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_name_pos(df):\n",
    "    name_pos = {}\n",
    "    \n",
    "    for name in set(df['Name']):\n",
    "        pos = df.loc[(df['Name']==name) & (df['Pos']!=0), 'Pos'].mode()\n",
    "        if len(pos) != 0:\n",
    "            name_pos[name] = pos[0]\n",
    "    \n",
    "    return name_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:50.268617Z",
     "start_time": "2019-05-26T09:32:50.258772Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_positions(df):\n",
    "    name_pos = generate_name_pos(df)\n",
    "    \n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        if df.loc[i, 'Pos'] == 0:\n",
    "            name = df.loc[i, 'Name']\n",
    "            if name in name_pos.keys():\n",
    "                df.loc[i, 'Pos'] = name_pos[name]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:51.176877Z",
     "start_time": "2019-05-26T09:32:51.169951Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_binary_positions(df):\n",
    "    zeros = [0 for i in range(df.shape[0])]\n",
    "    PG, SG, F, C = zeros.copy(), zeros.copy(), zeros.copy(), zeros.copy()\n",
    "        \n",
    "    for i in range(df.shape[0]):\n",
    "        if 'PG' in df.loc[i,'Pos']:\n",
    "            PG[i] = 1\n",
    "            \n",
    "        elif 'SG' in df.loc[i,'Pos']:\n",
    "            SG[i] = 1\n",
    "\n",
    "        elif 'C' in df.loc[i,'Pos']:\n",
    "            C[i] = 1\n",
    "            \n",
    "        else:\n",
    "            F[i] = 1\n",
    "            \n",
    "    df['PG'] = PG\n",
    "    df['SG'] = SG\n",
    "    df['F'] = F\n",
    "    df['C'] = C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T16:06:50.196829Z",
     "start_time": "2018-03-13T16:06:50.193649Z"
    },
    "collapsed": true
   },
   "source": [
    "### Name Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:53.321615Z",
     "start_time": "2019-05-26T09:32:53.277881Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NameStandardizer():\n",
    "    # Use the search function on Basketball-Reference.com to generate standard names\n",
    "    def parse_name(self, term, active_years):\n",
    "        search_url = 'https://www.basketball-reference.com/search/search.fcgi?hint=&search={term}&pid=&idx='\n",
    "        name_url = search_url.format(term=term.replace(' ','+'))\n",
    "        soup = BeautifulSoup(urlopen(name_url),'lxml')\n",
    "\n",
    "        #Check if there is ambiguity in the name\n",
    "        if soup.find('h1').get_text() != 'Search Results':\n",
    "            return soup.find('h1').get_text()\n",
    "\n",
    "\n",
    "        elif (soup.find('div', id='players', class_='current') == None):\n",
    "            if (len(term.split(' ')) > 2) or ('.' in term):\n",
    "                #Parse again without periods and with first two names\n",
    "                new_term = ' '.join(term.replace('.','').split(' ')[:2])\n",
    "                return self.parse_name(new_term, active_years)\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        else:        \n",
    "            items = soup.find('div', id='players', class_='current').find_all('div', class_='search-item-name')\n",
    "            candidates = []\n",
    "\n",
    "            for item in items:\n",
    "                name = item.find('a').get_text()\n",
    "\n",
    "                if '(' not in name:\n",
    "                    candidates.append(name)\n",
    "\n",
    "                else:\n",
    "                    career = name[name.find('(')+1:name.find(')')].split('-')\n",
    "                    if len(career) == 1:\n",
    "                        if int(career[0]) in active_years:\n",
    "                            candidates.append(name[:name.find(' (')])\n",
    "                    else:\n",
    "                        start = int(career[0])\n",
    "                        end = int(career[1])\n",
    "\n",
    "                        for year in active_years: \n",
    "                            if year in range(start, end+1):\n",
    "                                candidates.append(name[:name.find(' (')])\n",
    "                                break\n",
    "\n",
    "            if len(candidates) != 0:\n",
    "                for candidate in candidates:\n",
    "                    if term in candidate:\n",
    "                        return candidate\n",
    "                return candidates[0]\n",
    "\n",
    "            else:\n",
    "                return np.nan\n",
    "            \n",
    "            \n",
    "    def generate_standard_names(self, df, active_years):\n",
    "        names = list(set(df['Name']))\n",
    "        standard_names = []\n",
    "        errors, confusions = [], []\n",
    "        \n",
    "        for i, name in enumerate(tqdm(names)):\n",
    "            standard_name = self.parse_name(name, active_years)\n",
    "            \n",
    "            if name != standard_name:\n",
    "                print(\"{} From {} To {}\".format(i, name, standard_name))\n",
    "                \n",
    "                if standard_name == np.nan:\n",
    "                    errors.append(name)\n",
    "\n",
    "                elif ('G-League Stats' in standard_name) or ('International Stats' in standard_name):\n",
    "                    confusions.append(standard_name)\n",
    "                    \n",
    "                else:\n",
    "                    standard_names.append(standard_name)\n",
    "            else:\n",
    "                standard_names.append(standard_name)\n",
    "            \n",
    "            time.sleep(SECONDS_SLEEP)\n",
    "\n",
    "        return (standard_names, errors, confusions) \n",
    "    \n",
    "    \n",
    "    def standardize_names(self, df, standard_names, active_years):\n",
    "        names = list(set(df['Name']))\n",
    "\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        diff = [name for name in names if name not in standard_names]\n",
    "        print('{} names are standardized ...'.format(len(diff)))\n",
    "\n",
    "        names_conversion = {}\n",
    "\n",
    "        for name in tqdm(names):\n",
    "            if name in diff:\n",
    "                names_conversion[name] = self.parse_name(name, active_years)\n",
    "                time.sleep(SECONDS_SLEEP)\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            name = df.loc[i,'Name']\n",
    "            if name in names_conversion.keys():\n",
    "                df.loc[i,'Name'] = names_conversion[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T16:28:09.961055Z",
     "start_time": "2019-05-25T16:28:09.956201Z"
    }
   },
   "source": [
    "### Generate/Load Standardized Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:02:12.851421Z",
     "start_time": "2019-05-25T21:02:12.836934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if standard names are already generated\n",
    "if os.path.exists(os.path.join(DATA_DIR, 'Names', 'standard_names.npy')):\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'standard_names.npy'), \"rb\") as fp:\n",
    "        standard_names = pickle.load(fp)\n",
    "    \n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'confusions.npy'), \"rb\") as fp:\n",
    "        confusions = pickle.load(fp)\n",
    "    \n",
    "else:\n",
    "    # Generate standard names for all players from names shown in salary information from RotoGuru\n",
    "    df_salary = utils.csv_concatenate(os.path.join(DATA_DIR, 'DKSalary'), nested=True)\n",
    "\n",
    "    # Specify current years to avoid duplication across eras (from 2014 to 2019)\n",
    "    active_years = [2014+i for i in range(6)]\n",
    "\n",
    "    # Takes about 30 mins\n",
    "    standardizer = NameStandardizer()\n",
    "    standard_names, errors, confusions = standardizer.generate_standard_names(df_salary, active_years)\n",
    "\n",
    "    # Create a file containing standardized names\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'standard_names.npy'), \"wb\") as fp:\n",
    "        pickle.dump(standard_names, fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'errors.npy'), \"wb\") as fp:\n",
    "        pickle.dump(errors, fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, 'Names', 'confusions.npy'), \"wb\") as fp:\n",
    "        pickle.dump(confusions, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:02:13.820592Z",
     "start_time": "2019-05-25T21:02:13.812961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handle edge cases manually as some name searchs return only G-league stats but not NBA records\n",
    "# Cannot be differentiated from players who only played in the G-League at the moment\n",
    "print(confusions)\n",
    "standard_names = standard_names + ['Derrick Walton', 'CJ McCollum', 'Sheldon Mac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Names and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:13:36.593423Z",
     "start_time": "2019-05-25T21:02:15.734075Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seasons = ['2014-15', '2015-16', '2016-17', '2017-18', '2018-19']\n",
    "active_years = [2014+i for i in range(6)]\n",
    "\n",
    "standardizer = NameStandardizer()\n",
    "\n",
    "for season in seasons:\n",
    "    print('Processing the {} season ...'.format(season))\n",
    "    \n",
    "    # Standardize names for salary information\n",
    "    df_salary = utils.csv_concatenate(os.path.join(DATA_DIR, 'DKSalary', season))\n",
    "    standardizer.standardize_names(df_salary, standard_names, active_years)\n",
    "    fill_pos(df_salary)\n",
    "    \n",
    "    # Standardize names for boxscores\n",
    "    df_games = utils.csv_concatenate(os.path.join(DATA_DIR, 'Boxscores', season))\n",
    "    df_games['FPTS'] = utils.calculate_FPTS(df_games)\n",
    "    add_doubles(df_games)\n",
    "    df_games = df_games.loc[:, DF_VARIABLES]\n",
    "    standardizer.standardize_names(df_games, standard_names, active_years)\n",
    "    \n",
    "    # Merge two datasets and save to a csv file\n",
    "    df = pd.merge(df_salary.drop('Team', axis=1), df_games, on=['Name', 'Date'], how='inner')\n",
    "    df = df[df['Pos']!=0].sort_values(by=['Date','Team']).reset_index(drop=True)\n",
    "\n",
    "    # Add \"Value\" variable defined as a ratio between FPTS and Salary\n",
    "    df['Value'] = df['FPTS']/(df['Salary']/1000)\n",
    "    df['Value'] = df['Value'].replace(np.inf, 0).replace(-np.inf, 0)\n",
    "    \n",
    "    # Add binary positions for later use in EDA and modelling \n",
    "    add_binary_positions(df)\n",
    "    \n",
    "    columns = DF_VARIABLES.copy()\n",
    "    \n",
    "    for i, new_column in zip([1,3,4,7,44,45,46,47], ['Pos','Salary', 'Starter', 'Value','PG','SG','F','C']):\n",
    "        columns.insert(i, new_column)\n",
    "\n",
    "    df = df.loc[:, columns]\n",
    "    df.to_csv(os.path.join(DATA_DIR, 'Dataframes', 'Merged','df_{}.csv'.format(season)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

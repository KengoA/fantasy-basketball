{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T13:44:04.014284Z",
     "start_time": "2018-04-01T13:44:03.293233Z"
    },
    "scrolled": false
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This notebook first generates standardized names from fantasy salary information by querying Basketball-Reference.com, and then merge two datasets while adding fantasy stats based on DraftKings rules. Position information is also modified and added from salary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:05.924554Z",
     "start_time": "2019-05-26T09:32:05.420122Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from constants import DATA_DIR, SECONDS_SLEEP, DF_VARIABLES, URL_BBREF, SEARCH_FORMAT, SEASON_DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:07.439131Z",
     "start_time": "2019-05-26T09:32:07.435317Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Fantasy Stats from Boxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:45.478854Z",
     "start_time": "2019-05-26T09:32:45.465708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add additional columns for double double (DD) and triple double (TD)\n",
    "# Double digit in two or three of points, rebounds, assists, steals and blocks\n",
    "def add_doubles(df):\n",
    "    dd = [0 for _ in range(df.shape[0])]\n",
    "    td = [0 for _ in range(df.shape[0])]\n",
    "\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        doubles_count = 0\n",
    "        check_doubles = [\"PTS\", \"TRB\", \"AST\", \"STL\", \"BLK\"]\n",
    "\n",
    "        for stat in check_doubles:\n",
    "            if df.loc[i, stat] >= 10:\n",
    "                doubles_count += 1\n",
    "\n",
    "        if doubles_count >= 2:\n",
    "            dd[i] = 1\n",
    "        if doubles_count >= 3:\n",
    "            td[i] = 1\n",
    "\n",
    "    df[\"DD\"] = dd\n",
    "    df[\"TD\"] = td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Position Information on Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:47.683228Z",
     "start_time": "2019-05-26T09:32:47.676459Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_name_pos(df):\n",
    "    name_pos = {}\n",
    "\n",
    "    for name in set(df[\"Name\"]):\n",
    "        pos = df.loc[(df[\"Name\"] == name) & (df[\"Pos\"] != 0), \"Pos\"].mode()\n",
    "        if len(pos) != 0:\n",
    "            name_pos[name] = pos[0]\n",
    "\n",
    "    return name_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:50.268617Z",
     "start_time": "2019-05-26T09:32:50.258772Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_positions(df):\n",
    "    name_pos = generate_name_pos(df)\n",
    "\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        if df.loc[i, \"Pos\"] == 0:\n",
    "            name = df.loc[i, \"Name\"]\n",
    "            if name in name_pos.keys():\n",
    "                df.loc[i, \"Pos\"] = name_pos[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:51.176877Z",
     "start_time": "2019-05-26T09:32:51.169951Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_binary_positions(df):\n",
    "    zeros = [0 for i in range(df.shape[0])]\n",
    "    PG, SG, F, C = zeros.copy(), zeros.copy(), zeros.copy(), zeros.copy()\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if \"PG\" in df.loc[i, \"Pos\"]:\n",
    "            PG[i] = 1\n",
    "\n",
    "        elif \"SG\" in df.loc[i, \"Pos\"]:\n",
    "            SG[i] = 1\n",
    "\n",
    "        elif \"C\" in df.loc[i, \"Pos\"]:\n",
    "            C[i] = 1\n",
    "\n",
    "        else:\n",
    "            F[i] = 1\n",
    "\n",
    "    df[\"PG\"] = PG\n",
    "    df[\"SG\"] = SG\n",
    "    df[\"F\"] = F\n",
    "    df[\"C\"] = C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T16:06:50.196829Z",
     "start_time": "2018-03-13T16:06:50.193649Z"
    },
    "collapsed": true
   },
   "source": [
    "### Name Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:32:53.321615Z",
     "start_time": "2019-05-26T09:32:53.277881Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Use the search function on Basketball-Reference.com to generate standard names\n",
    "def parse_name(term, active_years):\n",
    "    name_url = URL_BBREF + SEARCH_FORMAT.format(term=term.replace(\" \", \"+\"))\n",
    "    soup = BeautifulSoup(urlopen(name_url), \"lxml\")\n",
    "\n",
    "    # Check if there is ambiguity in the name\n",
    "    if soup.find(\"h1\").get_text() != \"Search Results\":\n",
    "        return soup.find(\"h1\").get_text()\n",
    "\n",
    "    elif soup.find(\"div\", id=\"players\", class_=\"current\") == None:\n",
    "        if (len(term.split(\" \")) > 2) or (\".\" in term):\n",
    "            # Parse again without periods and with first two names\n",
    "            new_term = \" \".join(term.replace(\".\", \"\").split(\" \")[:2])\n",
    "            return parse_name(new_term, active_years)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    else:\n",
    "        items = soup.find(\"div\", id=\"players\", class_=\"current\").find_all(\n",
    "            \"div\", class_=\"search-item-name\"\n",
    "        )\n",
    "        candidates = []\n",
    "\n",
    "        for item in items:\n",
    "            name = item.find(\"a\").get_text()\n",
    "\n",
    "            if \"(\" not in name:\n",
    "                candidates.append(name)\n",
    "\n",
    "            else:\n",
    "                career = name[name.find(\"(\") + 1 : name.find(\")\")].split(\"-\")\n",
    "                if len(career) == 1:\n",
    "                    if int(career[0]) in active_years:\n",
    "                        candidates.append(name[: name.find(\" (\")])\n",
    "                else:\n",
    "                    start = int(career[0])\n",
    "                    end = int(career[1])\n",
    "\n",
    "                    for year in active_years:\n",
    "                        if year in range(start, end + 1):\n",
    "                            candidates.append(name[: name.find(\" (\")])\n",
    "                            break\n",
    "\n",
    "        if len(candidates) != 0:\n",
    "            for candidate in candidates:\n",
    "                if term in candidate:\n",
    "                    return candidate\n",
    "            return candidates[0]\n",
    "\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "def generate_standard_names(df, active_years):\n",
    "    names = list(set(df[\"Name\"]))\n",
    "    standard_names = []\n",
    "    errors, confusions = [], []\n",
    "\n",
    "    for i, name in enumerate(tqdm(names)):\n",
    "        standard_name = parse_name(name, active_years)\n",
    "\n",
    "        if name != standard_name:\n",
    "            print(\"{} From {} To {}\".format(i, name, standard_name))\n",
    "\n",
    "            if standard_name == np.nan:\n",
    "                errors.append(name)\n",
    "\n",
    "            elif (\"G-League Stats\" in standard_name) or (\n",
    "                \"International Stats\" in standard_name\n",
    "            ):\n",
    "                confusions.append(standard_name)\n",
    "\n",
    "            else:\n",
    "                standard_names.append(standard_name)\n",
    "        else:\n",
    "            standard_names.append(standard_name)\n",
    "\n",
    "        time.sleep(SECONDS_SLEEP)\n",
    "\n",
    "    return (standard_names, errors, confusions)\n",
    "\n",
    "def standardize_names(df, standard_names, active_years):\n",
    "    names = list(set(df[\"Name\"]))\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    diff = [name for name in names if name not in standard_names]\n",
    "    print(\"{} names are standardized ...\".format(len(diff)))\n",
    "\n",
    "    names_conversion = {}\n",
    "\n",
    "    for name in tqdm(names):\n",
    "        if name in diff:\n",
    "            names_conversion[name] = parse_name(name, active_years)\n",
    "            time.sleep(SECONDS_SLEEP)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        name = df.loc[i, \"Name\"]\n",
    "        if name in names_conversion.keys():\n",
    "            df.loc[i, \"Name\"] = names_conversion[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T16:28:09.961055Z",
     "start_time": "2019-05-25T16:28:09.956201Z"
    }
   },
   "source": [
    "### Generate/Load Standardized Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:02:12.851421Z",
     "start_time": "2019-05-25T21:02:12.836934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if standard names are already generated\n",
    "if os.path.exists(os.path.join(DATA_DIR, \"Names\", \"standard_names.npy\")):\n",
    "    with open(os.path.join(DATA_DIR, \"Names\", \"standard_names.npy\"), \"rb\") as fp:\n",
    "        standard_names = pickle.load(fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"Names\", \"confusions.npy\"), \"rb\") as fp:\n",
    "        confusions = pickle.load(fp)\n",
    "\n",
    "else:\n",
    "    # Generate standard names for all players from names shown in salary information from RotoGuru\n",
    "    df_salary = utils.csv_concatenate(os.path.join(DATA_DIR, \"DKSalary\"), nested=True)\n",
    "\n",
    "    # Specify current years to avoid duplication across eras (from 2014 to 2019)\n",
    "    active_years = [2014 + i for i in range(6)]\n",
    "\n",
    "    # Takes about 30 mins\n",
    "    standard_names, errors, confusions = generate_standard_names(\n",
    "        df_salary, active_years\n",
    "    )\n",
    "\n",
    "    # Create a file containing standardized names\n",
    "    with open(os.path.join(DATA_DIR, \"Names\", \"standard_names.npy\"), \"wb\") as fp:\n",
    "        pickle.dump(standard_names, fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"Names\", \"errors.npy\"), \"wb\") as fp:\n",
    "        pickle.dump(errors, fp)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"Names\", \"confusions.npy\"), \"wb\") as fp:\n",
    "        pickle.dump(confusions, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:02:13.820592Z",
     "start_time": "2019-05-25T21:02:13.812961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walter Lemon Jr. International Stats', 'Derrick Walton Jr. G-League Stats', 'C.J. McCollum G-League Stats', 'Sheldon McClellan G-League Stats']\n"
     ]
    }
   ],
   "source": [
    "# Handle edge cases manually as some name searchs return only G-league stats but not NBA records\n",
    "# Cannot be differentiated from players who only played in the G-League at the moment\n",
    "print(confusions)\n",
    "standard_names = standard_names + [\"Derrick Walton\", \"CJ McCollum\", \"Sheldon Mac\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Names and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T21:13:36.593423Z",
     "start_time": "2019-05-25T21:02:15.734075Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the 2014-15 season ...\n",
      "13 names are standardized ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6845de03d4294a22808ab8939b7dce72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Standardize names for salary information\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df_salary \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcsv_concatenate(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATA_DIR, \u001b[39m\"\u001b[39m\u001b[39mDKSalary\u001b[39m\u001b[39m\"\u001b[39m, season))\n\u001b[0;32m----> 9\u001b[0m standardize_names(df_salary, standard_names, active_years)\n\u001b[1;32m     10\u001b[0m fill_positions(df_salary)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Standardize names for boxscores\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 94\u001b[0m, in \u001b[0;36mstandardize_names\u001b[0;34m(df, standard_names, active_years)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m diff:\n\u001b[1;32m     93\u001b[0m         names_conversion[name] \u001b[39m=\u001b[39m parse_name(name, active_years)\n\u001b[0;32m---> 94\u001b[0m         time\u001b[39m.\u001b[39;49msleep(SECONDS_SLEEP)\n\u001b[1;32m     96\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m     97\u001b[0m     name \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[i, \u001b[39m\"\u001b[39m\u001b[39mName\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seasons = SEASON_DATES.keys()\n",
    "active_years = [2014 + i for i in range(len(seasons))]\n",
    "\n",
    "for season in seasons:\n",
    "    print(\"Processing the {} season ...\".format(season))\n",
    "\n",
    "    # Standardize names for salary information\n",
    "    df_salary = utils.csv_concatenate(os.path.join(DATA_DIR, \"DKSalary\", season))\n",
    "    standardize_names(df_salary, standard_names, active_years)\n",
    "    fill_positions(df_salary)\n",
    "\n",
    "    # Standardize names for boxscores\n",
    "    df_games = utils.csv_concatenate(os.path.join(DATA_DIR, \"Boxscores\", season))\n",
    "    df_games[\"FPTS\"] = utils.calculate_FPTS(df_games)\n",
    "    add_doubles(df_games)\n",
    "    df_games = df_games.loc[:, DF_VARIABLES]\n",
    "    standardize_names(df_games, standard_names, active_years)\n",
    "\n",
    "    # Merge two datasets and save to a csv file\n",
    "    df = pd.merge(\n",
    "        df_salary.drop(\"Team\", axis=1), df_games, on=[\"Name\", \"Date\"], how=\"inner\"\n",
    "    )\n",
    "    df = df[df[\"Pos\"] != 0].sort_values(by=[\"Date\", \"Team\"]).reset_index(drop=True)\n",
    "\n",
    "    # Add \"Value\" variable defined as a ratio between FPTS and Salary\n",
    "    df[\"Value\"] = df[\"FPTS\"] / (df[\"Salary\"] / 1000)\n",
    "    df[\"Value\"] = df[\"Value\"].replace(np.inf, 0).replace(-np.inf, 0)\n",
    "\n",
    "    # Add binary positions for later use in EDA and modelling\n",
    "    add_binary_positions(df)\n",
    "\n",
    "    columns = DF_VARIABLES.copy()\n",
    "\n",
    "    for i, new_column in zip(\n",
    "        [1, 3, 4, 7, 44, 45, 46, 47],\n",
    "        [\"Pos\", \"Salary\", \"Starter\", \"Value\", \"PG\", \"SG\", \"F\", \"C\"],\n",
    "    ):\n",
    "        columns.insert(i, new_column)\n",
    "\n",
    "    df = df.loc[:, columns]\n",
    "    df.to_csv(\n",
    "        os.path.join(DATA_DIR, \"Dataframes\", \"Merged\", \"df_{}.csv\".format(season)),\n",
    "        index=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2e9f85711d675251e4e6c92db989e987b0f16da61e903a803bff5971dd18ff93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
